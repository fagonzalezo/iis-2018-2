{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 3\n",
    "## Introducción a los sistemas inteligentes 2018-2\n",
    "\n",
    "**Fecha límite de entrega**: Domingo 23 de Diciembre_ antes de la medianoche (ver instrucciones de envío al final)\n",
    "\n",
    "Integrantes del grupo (máximo 3):\n",
    "\n",
    "* Nombre_1 ID_1\n",
    "* Nombre_2 ID_2\n",
    "* Nombre_3 ID_3\n",
    "\n",
    "___________\n",
    "\n",
    "## 1. Clasificación de aves\n",
    "### 1.1 Predicción directa\n",
    "* Descargue el conjunto de datos de aves de [aquí](https://drive.google.com/uc?export=download&id=1UMbXi30WNXTiEHbXtHCICO99H9IFiXrw).\n",
    "* Utilice Keras y el modelo pre-entrenado de MobileNet para clasificar las imágenes en el conjunto de datos de aves. Construya una matriz de confusión que relacione las clases de aves con las 10 clases más frecuentes de ImageNet que predice el modelo.\n",
    "\n",
    "### 1.2 Transfer learning\n",
    "* Utilice el modelo pre-entrenado MobileNet como un extractor de características. \n",
    "* Cree un nuevo modelo que reemplace la parte superior de MobileNet con dos capas de 256 y 6 neuronas, respectivamente.\n",
    "* Entrena al modelo con las imágenes de entrenamiento del conjunto de datos de aves.\n",
    "* Evalúe el rendimiento sobre el conjunto de datos de prueba que informa los resultados en una matriz de confusión. \n",
    "* Discuta los resultados.\n",
    "\n",
    "### 1.3 Fine-tunning\n",
    "* Siga el tutorial en esta [página](https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/) para construir un nuevo modelo que reemplace la parte superior de MobileNet con dos capas de 256 y 6 neuronas, respectivamente.\n",
    "* Permita que las últimas capas de la red convolucional se entrenen.\n",
    "* Entrena al modelo con las imágenes de entrenamiento del conjunto de datos de aves.\n",
    "* Evalúe el rendimiento sobre el conjunto de datos de prueba que informa los resultados en una matriz de confusión. \n",
    "* Compare con los resultados del anterior modelo. Discuta.\n",
    "\n",
    "## 2. Clasificación de escenas\n",
    "\n",
    "* Descargue las imágenes del conjunto de datos de escenas disponible [aquí](https://figshare.com/articles/15-Scene_Image_Dataset/7007177).\n",
    "* Aplique transfer learning para construir un modelo de clasificación siguiendo los pasos del punto 1.2\n",
    "* Aplique fine-tuning para construir un modelo de clasificación siguiendo los pasos del punto 1.3\n",
    "* Compare los resultados y contraste con los que obtuvo en el [Taller 2](https://github.com/fagonzalezo/iis-2018-2/blob/master/taller2.ipynb).\n",
    "_________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instrucciones de envío:**\n",
    "\n",
    "Este notebook debe enviarse a través del siguiente [File Request](https://www.dropbox.com/request/pQoxbTpCsl8H8JurwB3F)\n",
    "antes de la medianoche de la fecha límite. El archivo debe nombrarse como \n",
    "`iis-taller2-unalusername1-unalusername2-unalusername3.ipynb`, donde `unalusername` es el nombre de usuario asignado por la universidad (incluya los nombres de usuario de todos los miembros del grupo)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
